# ApacheSpark_Delta_Tables
Apache Spark is a core technology for large-scale data analytics. Microsoft Fabric provides support for Spark clusters, enabling you to analyze and process data in a Lakehouse at scale.

# The following was achieved in this sample walkthrough:
- Creating a Fabric Workspace
- Creating a Lakehouse
- Data uploaded
- Using Spark to explore data frame
- Creating a both managed and external delta tables
- Exploring table versioning
- Using of delta table for streaming data
- Stopping data streaming in Apache Spark

# Use the below resource
https://learn.microsoft.com/en-us/training/modules/use-apache-spark-work-files-lakehouse/
